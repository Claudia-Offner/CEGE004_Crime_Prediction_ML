{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "editorial-parts",
   "metadata": {
    "scrolled": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1549, 100)\n",
      "(665, 100)\n"
     ]
    }
   ],
   "source": [
    "%run Preprocessing.ipynb"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "theoretical-official",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Import packages\n",
    "import sklearn.feature_selection\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import tree\n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import GridSearchCV # RandomizedSearchCV\n",
    "from sklearn.metrics import accuracy_score,confusion_matrix\n",
    "import seaborn as sns\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "accessory-pulse",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Load train and test sets from Preprocessing file\n",
    "x_train = x_train\n",
    "y_train = y_train\n",
    "x_test = x_test\n",
    "y_test = y_test\n",
    "\n",
    "# Set classes based on classification complexity decided in pre-processing\n",
    "classes = {'LowCrime': 0, 'HighCrime': 1}\n",
    "\n",
    "# Function for plotting confusion matrix\n",
    "def plot_confusion_matrix(train_p, train, dom):\n",
    "    cf = confusion_matrix(train_p,train)\n",
    "    sns.heatmap(cf,annot=True,yticklabels=classes,xticklabels=classes,cmap='Blues', fmt='g')\n",
    "    plt.title(f'{dom} Confusion matrix')\n",
    "    plt.tight_layout()\n",
    "    # plt.savefig(f'{dom} Confusion matrix.png')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "english-stereo",
   "metadata": {},
   "source": [
    "## Feature Selection\n",
    "- Build the model using the pre-processed data\n",
    "- To avoid overfiting and slow computing (due to the increase in features from dummying as well as increasing dimensionality), selecting the most important features is important.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "conscious-orbit",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": "['PctKids2Par',\n 'racePctWhite',\n 'PctKidsBornNeverMar',\n 'PctFam2Par',\n 'PctYoungKids2Par',\n 'PctTeen2Par',\n 'racepctblack',\n 'pctWInvInc',\n 'pctWPubAsst',\n 'PctPersOwnOccup',\n 'PctPopUnderPov',\n 'FemalePctDiv',\n 'PctNotHSGrad',\n 'PctHousNoPhone',\n 'TotalPctDiv',\n 'MalePctDivorce',\n 'PctPersDenseHous',\n 'PctHousOwnOcc',\n 'PctHousLess3BR',\n 'medFamInc']"
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# select k best is a univariate method for feature selection:\n",
    "select = sklearn.feature_selection.SelectKBest(k=20)\n",
    "selected_features = select.fit(x_train, y_train)\n",
    "indices_selected = selected_features.get_support(indices=True)\n",
    "colnames_selected = [x.columns[I] for I in indices_selected]\n",
    "\n",
    "x_train_selected = x_train[colnames_selected]\n",
    "x_test_selected = x_test[colnames_selected]\n",
    "\n",
    "colnames_selected # 20 features selected\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fifteen-woman",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    },
    "scrolled": false
   },
   "source": [
    "## Build Decision tree #1\n",
    "\n",
    "We create a basic DecisionTreeClassifier, and then will slowly tune the parameters.\n",
    "- First, we check the **max depth**. The cell below will calculate the accuracy\n",
    "score for a max depth up to *n*. This is then plotted in a bar graph.\n",
    "\n",
    "NOTE: Why are we using the testing set at this stage? Should we perform k-fold validation and use that mean for this?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "turkish-buffalo",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Max depth hyper parameter choice plot\n",
    "def max_depth(n):\n",
    "    scores = {}\n",
    "    for i in range(3, n):\n",
    "        dtree = DecisionTreeClassifier(criterion='gini', max_depth=i)  # use the entropy rather than gini index\n",
    "        dtree.fit(x_train, y_train)\n",
    "        # Assess accuracy at this stage\n",
    "        clf = DecisionTreeClassifier()  # Create Decision Tree classifer object\n",
    "        clf = clf.fit(x_train,y_train)  # Train Decision Tree Classifer\n",
    "        y_pred = clf.predict(x_test)  # Predict the response for test dataset\n",
    "        #print(i, \"max_depth::\", \"Accuracy:\",metrics.accuracy_score(y_test, y_pred))\n",
    "        j = str(i)\n",
    "        depth_score = {j: accuracy_score(y_test, y_pred)}\n",
    "        scores.update(depth_score)\n",
    "    return scores\n",
    "d = max_depth(10)\n",
    "\n",
    "colors = list(\"rgbcmyk\")\n",
    "\n",
    "for key in d:\n",
    "    plt.bar([key], d[key], label=key, color=(0.2, 0.4, 0.6, 0.6))\n",
    "\n",
    "plt.title('Max Depth vs Test Data Accuracy')\n",
    "plt.xlabel('Max Depth')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim(0.80, 0.85)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "arbitrary-rendering",
   "metadata": {},
   "source": [
    "For this dataset, we have shown that the max_depth at 6 provides the highest accuracy. Therefore, the current model is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "greater-preference",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8390977443609022\n"
     ]
    }
   ],
   "source": [
    "dtree = DecisionTreeClassifier(criterion='gini', max_depth=6)  # use the entropy rather than gini index\n",
    "dtree = dtree.fit(x_train, y_train)\n",
    "y_pred = dtree.predict(x_test)  # Predict the response for test dataset\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "particular-handling",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'graphviz'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-49-ad52a4224477>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[1;31m# most stylised tree:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 2\u001B[1;33m \u001B[1;32mimport\u001B[0m \u001B[0mgraphviz\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      3\u001B[0m \u001B[0mdot_data\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mtree\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mexport_graphviz\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdtree\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mout_file\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;32mNone\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mfeature_names\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mfeatures\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mfilled\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;32mTrue\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mrounded\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;32mTrue\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mspecial_characters\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;32mTrue\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      4\u001B[0m \u001B[0mgraph\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mgraphviz\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mSource\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdot_data\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      5\u001B[0m \u001B[0mgraph\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mModuleNotFoundError\u001B[0m: No module named 'graphviz'"
     ]
    }
   ],
   "source": [
    "# most stylised tree:\n",
    "import graphviz\n",
    "dot_data = tree.export_graphviz(dtree, out_file=None, feature_names=features, filled=True, rounded=True, special_characters=True)\n",
    "graph = graphviz.Source(dot_data)\n",
    "graph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "conceptual-uniform",
   "metadata": {},
   "source": [
    "code adapted from https://medium.com/@mohtedibf/indepth-parameter-tuning-for-decision-tree-6753118a03c3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "expired-tomato",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "min_samples_splits = np.linspace(0.1, 1.0, 10, endpoint=True)\n",
    "train_results = []\n",
    "test_results = []\n",
    "for min_samples_split in min_samples_splits:\n",
    "   dt = DecisionTreeClassifier(min_samples_split=min_samples_split)\n",
    "   dt.fit(x_train, y_train)\n",
    "   train_pred = dt.predict(x_train)\n",
    "   false_positive_rate, true_positive_rate, thresholds =    roc_curve(y_train, train_pred)\n",
    "   roc_auc = auc(false_positive_rate, true_positive_rate)\n",
    "   train_results.append(roc_auc)\n",
    "   y_pred = dt.predict(x_test)\n",
    "   false_positive_rate, true_positive_rate, thresholds = roc_curve(y_test, y_pred)\n",
    "   roc_auc = auc(false_positive_rate, true_positive_rate)\n",
    "   test_results.append(roc_auc)\n",
    "    \n",
    "    \n",
    "from matplotlib.legend_handler import HandlerLine2D\n",
    "\n",
    "line1, = plt.plot(min_samples_splits, train_results, 'b', label='Train AUC')\n",
    "line2, = plt.plot(min_samples_splits, test_results, 'r', label='Test AUC')\n",
    "plt.legend(handler_map={line1: HandlerLine2D(numpoints=2)})\n",
    "plt.ylabel('AUC Score')\n",
    "plt.xlabel('min samples split')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "animated-adventure",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "seven-dressing",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "max_features = list(range(1,x_train.shape[1]))\n",
    "\n",
    "train_results = []\n",
    "test_results = []\n",
    "\n",
    "for max_feature in max_features:\n",
    "   dt = DecisionTreeClassifier(max_features=max_feature)\n",
    "   dt.fit(x_train, y_train)\n",
    "   train_pred = dt.predict(x_train)\n",
    "   false_positive_rate, true_positive_rate, thresholds = roc_curve(y_train, train_pred)\n",
    "   roc_auc = auc(false_positive_rate, true_positive_rate)\n",
    "   train_results.append(roc_auc)\n",
    "   y_pred = dt.predict(x_test)\n",
    "   false_positive_rate, true_positive_rate, thresholds = roc_curve(y_test, y_pred)\n",
    "   roc_auc = auc(false_positive_rate, true_positive_rate)\n",
    "   test_results.append(roc_auc)\n",
    "    \n",
    "from matplotlib.legend_handler import HandlerLine2D\n",
    "\n",
    "line1, = plt.plot(max_features, train_results, 'b', label='Train AUC')\n",
    "line2, = plt.plot(max_features, test_results, 'r', label='Test AUC')\n",
    "plt.legend(handler_map={line1: HandlerLine2D(numpoints=2)})\n",
    "plt.ylabel('AUC Score')\n",
    "plt.xlabel('max features')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "based-survivor",
   "metadata": {},
   "outputs": [],
   "source": [
    "kf =KFold(n_splits=4, shuffle=True, random_state=42)\n",
    "score = cross_val_score(tree.DecisionTreeClassifier(criterion='gini', max_depth=9, min_samples_split = 0.6, ccp_alpha = 0.012, max_features = 70), x, y, cv= kf, scoring=\"accuracy\")\n",
    "print(f'Scores for each fold are: {score}')\n",
    "print(f'Average score: {\"{:.2f}\".format(score.mean())}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "traditional-encounter",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "**Build the Decision tree #2** - applying pre-pruning techniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "available-booking",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = tree.DecisionTreeClassifier(criterion='gini', max_depth=9, min_samples_split = 0.6, ccp_alpha = 0.012, max_features = 70)\n",
    "path = clf.cost_complexity_pruning_path(x_train, y_train)\n",
    "ccp_alphas, impurities = path.ccp_alphas, path.impurities\n",
    "\n",
    "clfs = []\n",
    "for ccp_alpha in ccp_alphas:\n",
    "    clf = DecisionTreeClassifier(random_state=0, ccp_alpha=ccp_alpha)\n",
    "    clf.fit(x_train, y_train)\n",
    "    clfs.append(clf)\n",
    "print(\"Number of nodes in the last tree is: {} with ccp_alpha: {}\".format(\n",
    "      clfs[-1].tree_.node_count, ccp_alphas[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vocal-train",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_scores = [clf.score(x_train, y_train) for clf in clfs]\n",
    "test_scores = [clf.score(x_test, y_test) for clf in clfs]\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.set_xlabel(\"alpha\")\n",
    "ax.set_ylabel(\"accuracy\")\n",
    "ax.set_title(\"Accuracy vs alpha for training and testing sets\")\n",
    "ax.plot(ccp_alphas, train_scores, marker='o', label=\"train\",\n",
    "        drawstyle=\"steps-post\")\n",
    "ax.plot(ccp_alphas, test_scores, marker='o', label=\"test\",\n",
    "        drawstyle=\"steps-post\")\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "suited-fraction",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# # Testing pre pruning\n",
    "\n",
    "# params = {'max_depth': [2,4,6,8,10,12],  # why did we select these parameters?\n",
    "#          'min_samples_split': [2,3,4],\n",
    "#          'min_samples_leaf': [1,2]}\n",
    "# gcv = GridSearchCV(estimator=clf,param_grid=params)\n",
    "# gcv = gcv.fit(x_train,y_train)\n",
    "# y_pred = gcv.predict(x_test)  # Predict the response for test dataset\n",
    "# print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred)) # better accuracy score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "characteristic-detection",
   "metadata": {},
   "source": [
    "**K-Fold Classification** \n",
    "This will increase the number of times the test and train data is split, then will average out the accuracy scores. The cells below will increase the number of K up to 12, then plot the accuracy for the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "grand-football",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold, StratifiedKFold, cross_val_score\n",
    "\n",
    "\n",
    "kfold_scores = {}\n",
    "for i in range(2,12):\n",
    "    kf =KFold(n_splits=i, shuffle=True, random_state=42)\n",
    "    score = cross_val_score(tree.DecisionTreeClassifier(criterion='gini', max_depth=5), x, y, cv= kf, scoring=\"accuracy\")\n",
    "    #print(f'Scores for each fold are: {score}')\n",
    "    #print(f'Number of folds = {i} Average score: {\"{:.2f}\".format(score.mean())}')\n",
    "    res = {str(i): score.mean()}\n",
    "    kfold_scores.update(res)\n",
    "\n",
    "for key in kfold_scores:\n",
    "    plt.bar([key], kfold_scores[key], label=key, color=(0.2, 0.4, 0.6, 0.6))\n",
    "\n",
    "plt.title('K-Fold vs Test Data Accuracy')\n",
    "plt.xlabel('K')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim(0.7, 0.9)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "personalized-niger",
   "metadata": {},
   "outputs": [],
   "source": [
    "kf =KFold(n_splits=4, shuffle=True, random_state=42)\n",
    "score = cross_val_score(tree.DecisionTreeClassifier(criterion='gini', max_depth=6), x, y, cv= kf, scoring=\"accuracy\")\n",
    "print(f'Scores for each fold are: {score}')\n",
    "print(f'Average score: {\"{:.2f}\".format(score.mean())}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "respected-planning",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-pruning summary\n",
    "classes = ['Low Violence', 'High Violence']\n",
    "def plot_confusionmatrix(train_pred, train, dom):\n",
    "    print(f'{dom} Confusion matrix')\n",
    "    cf = confusion_matrix(train_pred,train)\n",
    "    sns.heatmap(cf,annot=True,yticklabels=classes\n",
    "               ,xticklabels=classes,cmap='Blues', fmt='g')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "# model = gcv.best_estimator_\n",
    "# model.fit(x_train,y_train)\n",
    "model = tree.DecisionTreeClassifier(criterion='gini', max_depth=5)\n",
    "model.fit(x_train, y_train)\n",
    "y_train_pred = model.predict(x_train)\n",
    "y_test_pred = model.predict(x_test)\n",
    "\n",
    "print(f'Train score {accuracy_score(y_train_pred,y_train)}')\n",
    "print(f'Test score {accuracy_score(y_test_pred,y_test)}')\n",
    "plot_confusionmatrix(y_train_pred,y_train,dom='Train')\n",
    "plot_confusionmatrix(y_test_pred,y_test,dom='Test')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deluxe-quality",
   "metadata": {},
   "source": [
    "**Build Decision Tree #3** - applying post-pruning techniques\n",
    "\n",
    "https://scikit-learn.org/stable/auto_examples/tree/plot_cost_complexity_pruning.html#sphx-glr-auto-examples-tree-plot-cost-complexity-pruning-py\n",
    "\n",
    "Total impurity of leaves vs effective alphas of pruned tree:\n",
    "\n",
    "Minimal cost complexity pruning recursively finds the node with the “weakest link”. The weakest link is characterized by an effective alpha, where the nodes with the smallest effective alpha are pruned first.\n",
    "\n",
    "Scikit-learn provides DecisionTreeClassifier.cost_complexity_pruning_path that returns the effective alphas and the corresponding total leaf impurities at each step of the pruning process. As alpha increases, more of the tree is pruned, which increases the total impurity of its leaves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "available-dryer",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Cost complexity pruning path\n",
    "path = clf.cost_complexity_pruning_path(x_train, y_train)\n",
    "ccp_alphas, impurities = path.ccp_alphas, path.impurities\n",
    "# Plot\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(ccp_alphas[:-1], impurities[:-1], marker='o', drawstyle=\"steps-post\")\n",
    "ax.set_xlabel(\"effective alpha\")\n",
    "ax.set_ylabel(\"total impurity of leaves\")\n",
    "ax.set_title(\"Total Impurity vs effective alpha for training set\")\n",
    "# the maximum effective alpha value is removed, because it is the trivial tree with only one node.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lyric-break",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Train a decision tree using the effective alphas.\n",
    "# The last value in ccp_alphas is the alpha value that prunes the whole tree, \n",
    "# this leaves the tree (clfs[-1]) with one node.\n",
    "\n",
    "clfs = []\n",
    "for ccp_alpha in ccp_alphas:\n",
    "    clf = DecisionTreeClassifier(random_state=0, ccp_alpha=ccp_alpha)\n",
    "    clf.fit(x_train, y_train)\n",
    "    clfs.append(clf)\n",
    "print(\"Number of nodes in the last tree is: {} with ccp_alpha: {}\".format(\n",
    "      clfs[-1].tree_.node_count, ccp_alphas[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "proper-integral",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Remove the last element in clfs and ccp_alphas, because it is the trivial tree with only one node.\n",
    "clfs = clfs[:-1]\n",
    "ccp_alphas = ccp_alphas[:-1]\n",
    "\n",
    "# Show that the number of nodes and tree depth decreases as alpha increases.\n",
    "node_counts = [clf.tree_.node_count for clf in clfs]\n",
    "depth = [clf.tree_.max_depth for clf in clfs]\n",
    "fig, ax = plt.subplots(2, 1)\n",
    "ax[0].plot(ccp_alphas, node_counts, marker='o', drawstyle=\"steps-post\")\n",
    "ax[0].set_xlabel(\"alpha\")\n",
    "ax[0].set_ylabel(\"number of nodes\")\n",
    "ax[0].set_title(\"Number of nodes vs alpha\")\n",
    "ax[1].plot(ccp_alphas, depth, marker='o', drawstyle=\"steps-post\")\n",
    "ax[1].set_xlabel(\"alpha\")\n",
    "ax[1].set_ylabel(\"depth of tree\")\n",
    "ax[1].set_title(\"Depth vs alpha\")\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exotic-deficit",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Compare accuracy vs alpha for training\n",
    "# When ccp_alpha is set to zero, the tree overfits; leading to a 100% training accuracy and 88% testing accuracy.\n",
    "# As alpha increases, more of the tree is pruned, thus creating a decision tree that generalizes better. \n",
    "\n",
    "train_scores = [clf.score(x_train, y_train) for clf in clfs]\n",
    "test_scores = [clf.score(x_test, y_test) for clf in clfs]\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.set_xlabel(\"alpha\")\n",
    "ax.set_ylabel(\"accuracy\")\n",
    "ax.set_title(\"Accuracy vs alpha for training and testing sets\")\n",
    "ax.plot(ccp_alphas, train_scores, marker='o', label=\"train\",\n",
    "        drawstyle=\"steps-post\")\n",
    "ax.plot(ccp_alphas, test_scores, marker='o', label=\"test\",\n",
    "        drawstyle=\"steps-post\")\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cordless-permission",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# fit the model again with the most suitable alpha i.e. 0.008\n",
    "# this alpha achieves the best test accuracy\n",
    "\n",
    "tree = DecisionTreeClassifier(ccp_alpha=0.01, random_state=40)\n",
    "tree.fit(x_train, y_train)\n",
    "y_train_pred=tree.predict(x_train)\n",
    "y_test_pred=tree.predict(x_test)\n",
    "\n",
    "print(\"Pruned tree train accuracy score: \", accuracy_score(y_train, y_train_pred),\n",
    "\"Pruned tree test accuracy score: \", accuracy_score(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eight-prototype",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extra graphs needed \n",
    "# https://scikit-learn.org/stable/auto_examples/tree/plot_iris_dtc.html\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "worse-consensus",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}